{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General.\n",
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "import math\n",
    "import random\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Data manipulation.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from libpysal import weights\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Torch.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "# Helper functions.\n",
    "from lstm_helper_fns import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aiohappyeyeballs==2.5.0\n",
      "aiohttp==3.11.13\n",
      "aiosignal==1.3.2\n",
      "appnope==0.1.4\n",
      "asttokens==3.0.0\n",
      "attrs==25.1.0\n",
      "beautifulsoup4==4.13.3\n",
      "certifi==2025.1.31\n",
      "charset-normalizer==3.4.1\n",
      "comm==0.2.2\n",
      "contourpy==1.3.1\n",
      "cycler==0.12.1\n",
      "debugpy==1.8.12\n",
      "decorator==5.1.1\n",
      "executing==2.2.0\n",
      "filelock==3.17.0\n",
      "fonttools==4.55.8\n",
      "frozenlist==1.5.0\n",
      "fsspec==2025.2.0\n",
      "geopandas==1.0.1\n",
      "idna==3.10\n",
      "ipykernel==6.29.5\n",
      "ipython==8.32.0\n",
      "jedi==0.19.2\n",
      "Jinja2==3.1.5\n",
      "joblib==1.4.2\n",
      "jupyter_client==8.6.3\n",
      "jupyter_core==5.7.2\n",
      "kiwisolver==1.4.8\n",
      "libpysal==4.12.1\n",
      "MarkupSafe==3.0.2\n",
      "matplotlib==3.10.0\n",
      "matplotlib-inline==0.1.7\n",
      "mpmath==1.3.0\n",
      "multidict==6.1.0\n",
      "nest-asyncio==1.6.0\n",
      "networkx==3.4.2\n",
      "numpy==2.2.2\n",
      "packaging==24.2\n",
      "pandas==2.2.3\n",
      "parso==0.8.4\n",
      "pexpect==4.9.0\n",
      "pillow==11.1.0\n",
      "platformdirs==4.3.6\n",
      "prompt_toolkit==3.0.50\n",
      "propcache==0.3.0\n",
      "psutil==6.1.1\n",
      "ptyprocess==0.7.0\n",
      "pure_eval==0.2.3\n",
      "Pygments==2.19.1\n",
      "pyogrio==0.10.0\n",
      "pyparsing==3.2.1\n",
      "pyproj==3.7.0\n",
      "python-dateutil==2.9.0.post0\n",
      "pytz==2025.1\n",
      "pyzmq==26.2.1\n",
      "requests==2.32.3\n",
      "scikit-learn==1.6.1\n",
      "scipy==1.15.1\n",
      "seaborn==0.13.2\n",
      "setuptools==75.8.0\n",
      "shapely==2.0.7\n",
      "six==1.17.0\n",
      "soupsieve==2.6\n",
      "stack-data==0.6.3\n",
      "sympy==1.13.1\n",
      "threadpoolctl==3.5.0\n",
      "torch==2.6.0\n",
      "torch-geometric==2.6.1\n",
      "torchvision==0.21.0\n",
      "tornado==6.4.2\n",
      "tqdm==4.67.1\n",
      "traitlets==5.14.3\n",
      "typing_extensions==4.12.2\n",
      "tzdata==2025.1\n",
      "urllib3==2.3.0\n",
      "wcwidth==0.2.13\n",
      "yarl==1.18.3\n"
     ]
    }
   ],
   "source": [
    "# List package versions.\n",
    "!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DailyCaseDataset(Dataset):\n",
    "    \"\"\"\n",
    "    The tabular form of the counties-daily case data for the LSTM.\n",
    "    Samples are in the form: input = window_size-7 days of cases, label = 7 days of cases.\n",
    "\n",
    "    Args:\n",
    "    - df: (pd.DataFrame) a num_counties, num_dates dataframe, containing float values.\n",
    "    - window: (int) an integer of the entire window used as input and label - e.g window=35\n",
    "    will give an input size of 35-7=28, with the label size always being 7.\n",
    "\n",
    "    Returns a dictionary containing the input and label (stored under 'input' and 'label')\n",
    "    of which the model is trained on \n",
    "    \"\"\"\n",
    "    def __init__(self, df, window):\n",
    "        self.data = df.to_numpy() # 2D array. \n",
    "        self.window = window\n",
    "        self.num_rows = self.data.shape[0]\n",
    "        self.num_cols = self.data.shape[1]\n",
    "\n",
    "        # Each row can provide (num_cols - window + 1) valid windows.\n",
    "        self.samples_per_row = self.num_cols - self.window + 1\n",
    "        self.data_size = self.num_rows * self.samples_per_row\n",
    "\n",
    "    def __len__(self):\n",
    "        # Ensure that we only allow indices that yield a full window of 'window' elements.\n",
    "        return self.data_size\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # Map 1D index to a 2D index.\n",
    "        row = idx // self.samples_per_row\n",
    "        col = idx % self.samples_per_row\n",
    "\n",
    "        # Window of the data for a given row.\n",
    "        data = torch.tensor(self.data[row, col:col+self.window], dtype=torch.float32)\n",
    "        \n",
    "        # Extract the label as the last 7 elements and the input as the preceding elements.\n",
    "        label = data[-7:]\n",
    "        input = data[:-7]\n",
    "            \n",
    "        return {'label': label, \n",
    "                'input': input}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples with window=35: 1186061\n",
      "Number of validation samples with window=35: 51324\n",
      "Number of testing samples with window=35: 110058\n"
     ]
    }
   ],
   "source": [
    "# Read in data.\n",
    "dftrain = pd.read_csv('/Users/jakecordery/Desktop/dissertation-york/data/processed/TRAIN_SCALED.csv')\n",
    "dfval = pd.read_csv('/Users/jakecordery/Desktop/dissertation-york/data/processed/VAL_SCALED.csv')\n",
    "dftest = pd.read_csv('/Users/jakecordery/Desktop/dissertation-york/data/processed/TEST_SCALED.csv')\n",
    "\n",
    "non_numeric_cols = ['County Name', 'State', 'countyFIPS']\n",
    "dftrain.drop(non_numeric_cols, axis=1, inplace=True)\n",
    "dfval.drop(non_numeric_cols, axis=1, inplace=True)\n",
    "dftest.drop(non_numeric_cols, axis=1, inplace=True)\n",
    "\n",
    "print(f\"Number of training samples with window=35: {len(DailyCaseDataset(dftrain, window=35))}\")\n",
    "print(f\"Number of validation samples with window=35: {len(DailyCaseDataset(dfval, window=35))}\")\n",
    "print(f\"Number of testing samples with window=35: {len(DailyCaseDataset(dftest, window=35))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # Settings.\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    num_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    The LSTM architecture used to determine the correct hyperparameters, \n",
    "    containing options to add dropout, attention or make the model bidirectional.\n",
    "    \n",
    "    Args:\n",
    "    - hidden_size, num_layers, input_size: int.\n",
    "    Optional: \n",
    "    - dropout, bidirectional: bool.\n",
    "    - num_heads: int.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 hidden_size, \n",
    "                 num_layers, \n",
    "                 input_size, \n",
    "                 bidirectional=False, \n",
    "                 dropout=False, \n",
    "                 num_heads=0):\n",
    "        super(LSTM, self).__init__()\n",
    "        # input_size should be the length of the input sequence (i.e 21, 28, 35 etc.)\n",
    "        # hidden_size is 64-128.\n",
    "        # num_layers is either 1 or 2.\n",
    "        # bi-lstm and attention leads to overfitting with nl 2 and hs 128,\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, \n",
    "                            hidden_size=hidden_size, \n",
    "                            num_layers=num_layers, \n",
    "                            bias=True, \n",
    "                            batch_first=True, # Meaning shapes should lead with batch_size.\n",
    "                            dropout=0.0, # Does nothing with num_layers = 1.\n",
    "                            bidirectional=bidirectional,\n",
    "                            proj_size=0, \n",
    "                            dtype=None)\n",
    "        \n",
    "        # Determines whether dropout or attention is used in the model.\n",
    "        self.dropoutbool = dropout\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        fc_in = hidden_size * 2 if bidirectional else hidden_size # Bidirectional has double hidden size.\n",
    "\n",
    "        if num_heads > 0: # Raises error if num_heads=0.\n",
    "            self.multihead_attn = nn.MultiheadAttention(embed_dim=fc_in, num_heads=num_heads, batch_first=True)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "        # Fully connected layer - \n",
    "        self.fc1 = nn.Linear(in_features=fc_in,\n",
    "                            out_features=7, #fc_in // 2, # Output 7 days.\n",
    "                            bias=True)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_len, input_size).\n",
    "        x, _ = self.lstm(x) # (batch_size, seq_len, fc_in).\n",
    "        \n",
    "        # Apply attention where query, key, and value are the LSTM outputs.\n",
    "        if self.num_heads > 0:\n",
    "            x, attn_weights = self.multihead_attn(x, x, x)\n",
    "        \n",
    "        # Apply dropout.\n",
    "        if self.dropoutbool:\n",
    "            x = self.dropout(x)\n",
    "            \n",
    "        return self.fc1(F.relu(x)) # (batch_size, 7).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad\n",
    "def test(model, dl, loss_fn, show_res=True):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    - model: torch.nn.Module.\n",
    "    - dl: torch.utils.data.DataLoader.\n",
    "    - loss_fn: torch.nn NOT torch.Functional type.\n",
    "    - show_res (optional): True, show a random set of 9 results.\n",
    "\n",
    "    Returns the average loss of the model on the dataloader.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    r = random.randint(0, len(dl))\n",
    "    for i, data in enumerate(dl):\n",
    "        input, label = data[f'input'].to(CFG.device), data['label'].to(CFG.device)\n",
    "\n",
    "        output = model(input)\n",
    "        loss = loss_fn(output, label)\n",
    "        total_loss += loss.item()\n",
    "            \n",
    "        # Show a random sample.\n",
    "        if show_res and i == r:\n",
    "            rrow = random.randint(1, input.shape[0]-10) # Random sample from batch.\n",
    "            l, o = detach_np(label[rrow:rrow+9]), detach_np(output[rrow:rrow+9])\n",
    "            print(f\"Validation/test predictions\")\n",
    "            display_preds(label=l, output=o, loss=loss_fn(l, o).item())\n",
    "    \n",
    "    return total_loss / (len(dl)) # Average test loss over all batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dl, val_dl, hparams, save_loc, show_res=True, show_epoch_acc=True):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    - model: torch.nn.Module.\n",
    "    - train_dl: torch.utils.data.DataLoader.\n",
    "    - val_dl: torch.utils.data.DataLoader, if entered as None, then validation is skipped.\n",
    "    - hparams: dict consisting of keys: op, lf, is, bs, lr, hs and nl.\n",
    "    - save_loc: str containing the save paths of the model weights.\n",
    "    - show_res (optional): True, display a subset of results from random batch.\n",
    "    - show_epoch_acc (optional): True, display the progress of the training (and optionally \n",
    "    the validation) accuracies of the model every epoch.\n",
    "\n",
    "    Returns:\n",
    "    - tr_losses, val_losses: np.array containing the losses for each epoch in training and validation.\n",
    "    OR\n",
    "    - tr_losses: np.array if val_dl == None.\n",
    "    \"\"\"\n",
    "    optimizer, loss_fn, input_size = hparams['op'], hparams['lf'], hparams['is']\n",
    "    batch_size, lr, hs, num_layers = hparams['bs'], hparams['lr'], hparams['hs'], hparams['nl']\n",
    "\n",
    "    # Create a new folder for weights based on the existing folders. e.g. LSTM01 makes LSTM02.\n",
    "    os.makedirs(save_loc, exist_ok=True)\n",
    "    save_loc = create_weights_folder(save_loc)\n",
    "\n",
    "    # Random batch to display samples from.\n",
    "    r = random.randint(0, len(train_dl)-1)\n",
    "\n",
    "    tr_losses = np.array([])\n",
    "    val_losses = np.array([])\n",
    "\n",
    "    for i, e in enumerate(range(1, CFG.num_epochs+1)):\n",
    "        model.train() # Renew training status after validation.\n",
    "        epoch_loss = 0\n",
    "        print(f\"{'-' * 20} \\nEpoch {e}\\n {'-' * 20}\")\n",
    "\n",
    "        for i, data in tqdm(enumerate(train_dl)):\n",
    "            input, label = data['input'].to(CFG.device), data['label'].to(CFG.device)\n",
    "\n",
    "            output = model(input)\n",
    "            output = output.reshape(input.shape[0], 7)\n",
    "            loss = loss_fn(output, label)\n",
    "            \n",
    "            # Backpropagation.\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # Show a random sample.\n",
    "            if show_res and i == r:\n",
    "                rrow = random.randint(1, input.shape[0]-10) # Random samples from batch.\n",
    "                l, o = detach_np(label[rrow:rrow+9]), detach_np(output[rrow:rrow+9])\n",
    "                print(f\"Training predictions:\")\n",
    "                display_preds(label=l, output=o, loss=1)#loss_fn(l, o).item())\n",
    "        \n",
    "        # Convert the loss from MSE to RMSE, print loss and av. accuracy.\n",
    "        epoch_loss /= (len(train_dl))\n",
    "        tr_losses = np.append(tr_losses, epoch_loss)\n",
    "        print(f\"Current training loss: {epoch_loss}\")\n",
    "\n",
    "        # Save model separately every epoch.\n",
    "        model_name = f\"E{e}_BS{str(batch_size)}_IN{input_size}_LR{str(lr)[2:]}_HS{str(hs)}_NL{str(num_layers)}.pth\"\n",
    "        save_path = os.path.join(save_loc, model_name)\n",
    "        torch.save(model, save_path)\n",
    "\n",
    "        # Validate the model.\n",
    "        if val_dl != None:\n",
    "            val_loss = test(model, val_dl, loss_fn)\n",
    "            print(f\"Current validation loss: {val_loss}\")\n",
    "            val_losses = np.append(val_losses, val_loss)\n",
    "\n",
    "            # Early stopping when val_loss has been unchanged for 50 epochs.\n",
    "            if e > 50:\n",
    "                mean_loss = np.mean(val_losses[-50:])\n",
    "                if mean_loss + 1e-4 > val_loss or mean_loss - 1e-4 < val_loss: # Small tolerance value.\n",
    "                    print(f\"Stopped training at epoch {e}, with a validation loss of: {val_loss}\")\n",
    "                    return tr_losses, val_losses\n",
    "\n",
    "        # After each epoch show the progress of the model.\n",
    "        if show_epoch_acc:\n",
    "            plot_accs(tr_losses, val_losses)\n",
    "\n",
    "    if val_dl != None:\n",
    "        return tr_losses, val_losses\n",
    "    else:\n",
    "        return tr_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find suitable correct hyperparameters, running min viable training loops.\n",
    "def train_models():\n",
    "    lr = 1e-4\n",
    "    weight_decay = 1e-5\n",
    "    \n",
    "    windows =[28, 35, 42, 49]\n",
    "    hiddens = [64, 128, 256]\n",
    "    num_layers = [1, 2]\n",
    "    batch_sizes = [32, 128, 1024]\n",
    "\n",
    "    save_loc = f'/Users/jakecordery/Desktop/dissertation-york/models/weights'\n",
    "\n",
    "    for w in windows:\n",
    "        for hs in hiddens:\n",
    "            for nl in num_layers:\n",
    "                for bs in batch_sizes:\n",
    "                    hparams = {\n",
    "                        'op': Adam(model.parameters(), lr=lr, weight_decay=weight_decay), \n",
    "                        'lf': nn.MSELoss(), \n",
    "                        'is': w, \n",
    "                        'bs': bs, \n",
    "                        'lr': lr, \n",
    "                        'hs': hs, \n",
    "                        'nl': nl\n",
    "                        }\n",
    "                    \n",
    "                train_ds = DailyCaseDataset(dftrain, window=w)\n",
    "                val_ds = DailyCaseDataset(dfval, window=w)\n",
    "\n",
    "                train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True, drop_last=True)\n",
    "                val_dl = DataLoader(val_ds, batch_size=bs, shuffle=True, drop_last=True)\n",
    "\n",
    "                model = LSTM(hidden_size=hs, \n",
    "                             num_layers=nl, \n",
    "                             input_size=w, \n",
    "                             bidirectional=False, \n",
    "                             dropout=False, \n",
    "                             num_heads=0).to(CFG.device)\n",
    "                \n",
    "                train_errs, val_errs = train(model, train_dl, val_dl, hparams, save_loc)\n",
    "                \n",
    "#train_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsemblePretrained(nn.Module):\n",
    "    \"\"\"\n",
    "    A fully connected layer which learns to weight the outputs of pretrained models.\n",
    "\n",
    "    Args:\n",
    "    - models: list of (pretrained) torch models.\n",
    "    - num_heads: int of number of attention heads <- num_heads=0 means no attention.\n",
    "    \"\"\"\n",
    "    def __init__(self, models):\n",
    "        super(EnsemblePretrained, self).__init__()  \n",
    "        self.models = models\n",
    "        self.m1, self.m2, self.m3 = models\n",
    "        self.input_dims_per_model = [28, 35, 42]\n",
    "        self.m_in1, self.m_in2, self.m_in3 = self.input_dims_per_model\n",
    "\n",
    "        self.input_dim = 0\n",
    "        self.output_dim = 7\n",
    "\n",
    "        # Find input dimension.\n",
    "        for model in self.models:\n",
    "            # Assuming fc1 is the final layer in model.\n",
    "            out_dim = model.fc1.out_features\n",
    "            self.input_dim += out_dim\n",
    "\n",
    "        self.fc = nn.Linear(in_features=self.input_dim,\n",
    "                            out_features=self.output_dim,\n",
    "                            bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = x[:, -self.m_in1:]\n",
    "        x2 = x[:, -self.m_in2:]\n",
    "        x3 = x[:, -self.m_in3:]\n",
    "\n",
    "        f1 = torch.jit.fork(self.m1, x1) # Where f stands for future.\n",
    "        f2 = torch.jit.fork(self.m2, x2)\n",
    "        f3 = torch.jit.fork(self.m3, x3)\n",
    "\n",
    "        # Wait for outputs.\n",
    "        x1_out = torch.jit.wait(f1)\n",
    "        x2_out = torch.jit.wait(f2)\n",
    "        x3_out = torch.jit.wait(f3)\n",
    "\n",
    "        X = torch.concat([x1_out, x2_out, x3_out], dim=1)\n",
    "\n",
    "        return self.fc(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleConnected(nn.Module):\n",
    "    \"\"\" \n",
    "    A model which concatenates the hidden states of three LSTM models, then outputs a 7 day forecast for the number of COVID cases.\n",
    "\n",
    "    Args: \n",
    "    - info: dict containing the hyperparameters of the layers.\n",
    "            - in1,2,3 = the LSTM input sizes.\n",
    "            - hidden1,2,3 = the LSTM hidden sizes.\n",
    "            - nl1,2,3 = the number of layers of each branch.\n",
    "            - nh = the number of attention heads.     \n",
    "    - dropout_bool: bool, include dropout or not.\n",
    "    \"\"\"\n",
    "    def __init__(self, info, dropout_bool):\n",
    "        super(EnsembleConnected, self).__init__()\n",
    "        self.lstm_in1 = info['in1']-7\n",
    "        self.lstm_in2 = info['in2']-7\n",
    "        self.lstm_in3 = info['in3']-7\n",
    "\n",
    "\n",
    "        self.hidden1 = info['hidden1']\n",
    "        self.hidden2 = info['hidden2']\n",
    "        self.hidden3 = info['hidden3']\n",
    "        \n",
    "        self.nl1 = info['nl1']\n",
    "        self.nl2 = info['nl2']\n",
    "        self.nl3 = info['nl3']\n",
    "\n",
    "        self.num_heads = info['nh']\n",
    "        # Embed dim must be divisible by number of heads!\n",
    "        # Hence add a few neurons if needed to match the shapes.\n",
    "        self.embed_dim1, self.hidden1 = self.match_embed_dim(self.lstm_in1, self.hidden1)\n",
    "        self.embed_dim2, self.hidden2 = self.match_embed_dim(self.lstm_in2, self.hidden2)\n",
    "        self.embed_dim3, self.hidden3 = self.match_embed_dim(self.lstm_in3, self.hidden3)\n",
    "\n",
    "\n",
    "        self.fc1_in = self.lstm_in1 + self.lstm_in2 + self.lstm_in3\n",
    "        self.fc1_out = self.fc1_in // 2\n",
    "        self.fc2_out = 7\n",
    "\n",
    "        self.lstm1 = nn.LSTM(input_size=self.lstm_in1,\n",
    "                             hidden_size=self.hidden1,\n",
    "                             num_layers=self.nl1,\n",
    "                             bias=True,\n",
    "                             batch_first=True)\n",
    "        \n",
    "        self.lstm2 = nn.LSTM(input_size=self.lstm_in2,\n",
    "                             hidden_size=self.hidden2,\n",
    "                             num_layers=self.nl2,\n",
    "                             bias=True,\n",
    "                             batch_first=True)\n",
    "        \n",
    "        self.lstm3 = nn.LSTM(input_size=self.lstm_in3,\n",
    "                             hidden_size=self.hidden3,\n",
    "                             num_layers=self.nl3,\n",
    "                             bias=True,\n",
    "                             batch_first=True)\n",
    "        \n",
    "        if self.num_heads > 0:\n",
    "            self.attention1 = nn.MultiheadAttention(embed_dim=self.embed_dim1,\n",
    "                                                   num_heads=self.num_heads)\n",
    "            self.attention2 = nn.MultiheadAttention(embed_dim=self.embed_dim2,\n",
    "                                                   num_heads=self.num_heads)\n",
    "            self.attention3 = nn.MultiheadAttention(embed_dim=self.embed_dim3,\n",
    "                                                   num_heads=self.num_heads)\n",
    "            self.fc1_in = self.embed_dim1 + self.embed_dim2 + self.embed_dim3\n",
    "            \n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=self.fc1_in,\n",
    "                             out_features=self.fc1_out)\n",
    "        \n",
    "        self.dropout_bool = dropout_bool\n",
    "        if self.dropout_bool:\n",
    "            self.dropout = nn.Dropout()\n",
    "        \n",
    "        self.fc2 = nn.Linear(in_features=self.fc1_out,\n",
    "                             out_features=self.fc2_out)\n",
    "    \n",
    "    def match_embed_dim(self, lstm_in, lstm_hidden):\n",
    "        plus_neurons = 8 - (lstm_in + lstm_hidden) % self.num_heads\n",
    "        return lstm_in + lstm_hidden + plus_neurons, lstm_hidden + plus_neurons\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Slice input for each branch.\n",
    "        x1 = x[:, -self.lstm_in1:]\n",
    "        x2 = x[:, -self.lstm_in2:]\n",
    "        x3 = x[:, -self.lstm_in3:]\n",
    "\n",
    "        # If attention==True, save copies for skip connection.\n",
    "        if self.num_heads > 0:\n",
    "            a1 = x1.clone()\n",
    "            a2 = x2.clone()\n",
    "            a3 = x3.clone()\n",
    "\n",
    "        # Compute the LSTM outputs concurrently.\n",
    "        f1 = torch.jit.fork(self.lstm1, x1)\n",
    "        f2 = torch.jit.fork(self.lstm2, x2)\n",
    "        f3 = torch.jit.fork(self.lstm3, x3)\n",
    "\n",
    "        x1_out, _ = torch.jit.wait(f1)\n",
    "        x2_out, _ = torch.jit.wait(f2)\n",
    "        x3_out, _ = torch.jit.wait(f3)\n",
    "\n",
    "        x1_out = F.relu(x1_out)\n",
    "        x2_out = F.relu(x2_out)\n",
    "        x3_out = F.relu(x3_out)\n",
    "\n",
    "        if self.num_heads > 0:\n",
    "            # Concatenate the original input with LSTM output per branch.\n",
    "            x1_cat = torch.cat([x1_out, a1], dim=1)\n",
    "            x2_cat = torch.cat([x2_out, a2], dim=1)\n",
    "            x3_cat = torch.cat([x3_out, a3], dim=1)\n",
    "            \n",
    "            x1_attn, _ = self.attention1(x1_cat, x1_cat, x1_cat)\n",
    "            x2_attn, _ = self.attention2(x2_cat, x2_cat, x2_cat)\n",
    "            x3_attn, _ = self.attention3(x3_cat, x3_cat, x3_cat)\n",
    "        else:\n",
    "            x1_attn, x2_attn, x3_attn = x1_out, x2_out, x3_out\n",
    "\n",
    "        # Concatenate outputs from all branches along sequence dimension.\n",
    "        X = torch.cat([x1_attn, x2_attn, x3_attn], dim=1)\n",
    "\n",
    "        # Fully connected, dropout and ReLU.\n",
    "        X = F.relu(self.fc1(X))\n",
    "        if self.dropout_bool:\n",
    "            X = self.dropout(X)\n",
    "        return self.fc2(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrain models.\n",
    "in_sizes = [35, 42, 49]\n",
    "bs, hs, nl, lr, wd = 1024, 128, 2, 1e-4, 1e-5\n",
    "\n",
    "for in_size in in_sizes:\n",
    "    model = LSTM(hs, nl, in_size-7)\n",
    "    hparams = {'op': Adam(model.parameters(), lr=lr, weight_decay=wd), \n",
    "            'lf': nn.MSELoss(), \n",
    "            'is': in_size-7, 'bs': bs, 'lr': lr, 'hs': hs, 'nl': nl}\n",
    "\n",
    "    train_dl = DataLoader(DailyCaseDataset(dftrain, window=in_size), batch_size=bs, shuffle=True, drop_last=True)\n",
    "    val_dl = DataLoader(DailyCaseDataset(dfval, window=in_size), batch_size=bs, shuffle=True, drop_last=True)\n",
    "\n",
    "    save_loc = 'pretrained_models/weights'\n",
    "\n",
    "    #trloss, vloss = train(model, train_dl, val_dl, hparams, save_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models.\n",
    "paths = [\n",
    "        '/Users/jakecordery/Desktop/dissertation-york/models/architectures/E2_BS1024_LR0001_HS128_NL2.pth',\n",
    "        '/Users/jakecordery/Desktop/dissertation-york/models/architectures/E16_BS1024_LR0001_HS128_NL2.pth',\n",
    "        '/Users/jakecordery/Desktop/dissertation-york/models/architectures/E15_BS1024_LR0001_HS128_NL2.pth'\n",
    "]\n",
    "models = load_model_list(paths, CFG.device)\n",
    "ensemble_pretrained = EnsemblePretrained(models=models)\n",
    "\n",
    "lr = 1e-4\n",
    "wd = 1e-5\n",
    "bs = 1024\n",
    "hs = 128\n",
    "nl = 2\n",
    "\n",
    "info = {\n",
    "    'in1': in_sizes[0], \n",
    "    'in2': in_sizes[1], \n",
    "    'in3': in_sizes[2],\n",
    "    'hidden1': hs, \n",
    "    'hidden2': hs, \n",
    "    'hidden3': hs,\n",
    "    'nl1': nl, \n",
    "    'nl2': nl, \n",
    "    'nl3': nl, \n",
    "    'nh': 8\n",
    "}\n",
    "ensemble_connected = EnsembleConnected(info=info, dropout_bool=True).to(CFG.device)\n",
    "\n",
    "hparams1 = {'op': Adam(ensemble_pretrained.parameters(), lr=lr, weight_decay=wd), \n",
    "            'lf': nn.MSELoss(), \n",
    "            'is': in_sizes, \n",
    "            'bs': bs, \n",
    "            'lr': lr, \n",
    "            'hs': hs, \n",
    "            'nl': nl\n",
    "}\n",
    "\n",
    "hparams2 = {'op': Adam(ensemble_connected.parameters(), lr=lr, weight_decay=wd), \n",
    "            'lf': nn.MSELoss(), \n",
    "            'is': in_sizes, \n",
    "            'bs': bs, \n",
    "            'lr': lr, \n",
    "            'hs': hs, \n",
    "            'nl': nl\n",
    "}\n",
    "\n",
    "# Create dataloaders (same for both models).\n",
    "train_dl = DataLoader(DailyCaseDataset(dftrain, window=49), batch_size=bs, shuffle=True, drop_last=True)\n",
    "val_dl = DataLoader(DailyCaseDataset(dfval, window=49), batch_size=bs, shuffle=True, drop_last=True)\n",
    "test_dl = DataLoader(DailyCaseDataset(dftest, window=49), batch_size=bs, shuffle=True, drop_last=True)\n",
    "\n",
    "save_loc = 'connected_vs_pretrained/weights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which produces better results - the different range LSTMs trained separately or altogether?\n",
    "#tr_loss_sep, val_loss_sep = train(model=ensemble_pretrained, train_dl=train_dl, val_dl=val_dl, hparams=hparams1, save_loc=save_loc)\n",
    "tr_loss_al, val_loss_al = train(model=ensemble_connected, train_dl=train_dl, val_dl=val_dl, hparams=hparams2, save_loc=save_loc)  \n",
    "# Connected model produces better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "# Merge train, val and test sets.\n",
    "dftrain = pd.read_csv('/Users/jakecordery/Desktop/dissertation-york/data/processed/TRAIN_SCALED.csv')\n",
    "dfval = pd.read_csv('/Users/jakecordery/Desktop/dissertation-york/data/processed/VAL_SCALED.csv') # OVER HALF HAVE NANS.\n",
    "dftest = pd.read_csv('/Users/jakecordery/Desktop/dissertation-york/data/processed/TEST_SCALED.csv')\n",
    "\n",
    "# From the training, validation and testing sets, choose the 16 most populous counties:\n",
    "# Los Angeles, CA; Cook, IL; Harris, TX; Maricopa, AZ; San Diego, CA; Orange, CA;\n",
    "# Miami-Dada, FL; Dallas, TX; Kings, NY; Riverside, CA; Clark, NV; King, Washington; \n",
    "# Queens, NY; Tarrant, TX; San Bernardino, CA; Bexar, TX.\n",
    "\n",
    "counties = [\"Los Angeles County\", \"Harris County\", \"Maricopa County\", \"San Diego County\", \n",
    "            \"Orange County\", \"Dallas County\", \"Kings County\", \"Riverside County\", \n",
    "            \"Clark County\", \"King County\", \"Queens County\", \"Tarrant County\", \"San Bernardino County\", \"Bexar County\"]\n",
    "states = [\"CA\", \"TX\", \"AZ\", \"CA\", \"CA\", \"TX\", \"NY\", \"CA\", \"NV\", \"WA\", \"NY\", \"TX\", \"CA\", \"TX\"]\n",
    "\n",
    "# Create a DataFrame filter\n",
    "pairs = set(zip(counties, states))\n",
    "mask_train = dftrain.apply(lambda row: (row[\"County Name\"].strip(), row[\"State\"]) in pairs, axis=1)\n",
    "mask_val   = dfval.apply(lambda row: (row[\"County Name\"].strip(), row[\"State\"]) in pairs, axis=1)\n",
    "mask_test  = dftest.apply(lambda row: (row[\"County Name\"].strip(), row[\"State\"]) in pairs, axis=1)\n",
    "\n",
    "# Apply the filters.\n",
    "dftrain_f = dftrain[mask_train].copy()\n",
    "dfval_f   = dfval[mask_val].copy()\n",
    "dftest_f  = dftest[mask_test].copy()\n",
    "\n",
    "dftrain_f.reset_index(drop=True, inplace=True)\n",
    "dfval_f.reset_index(drop=True, inplace=True)\n",
    "dftest_f.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Drop non-numerical columns.\n",
    "non_numeric = ['Unnamed: 0', 'countyFIPS', 'County Name', 'State']\n",
    "dftrain_f = dftrain_f.drop(columns=non_numeric, axis=0)\n",
    "dfval_f   = dfval_f.drop(columns=non_numeric, axis=0)\n",
    "dftest_f  = dftest_f.drop(columns=non_numeric, axis=0)\n",
    "\n",
    "\n",
    "# Merge dataframes in order (train, val, then test).\n",
    "df = pd.concat([dftrain_f, dfval_f, dftest_f], axis=1, ignore_index=True)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass dataframe to the test entire display function.\n",
    "model = torch.load('/Users/jakecordery/Desktop/dissertation-york/models/architectures/connected_vs_pretrained/weights/LSTM17/E17_BS1024_LR0001_HS128_NL2.pth',\n",
    "                   weights_only=False, map_location=CFG.device)\n",
    "res = test_entire_set(model=model, df=df, window_size=49, batch_size=1024, show_train=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
